<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!-- saved from url=(0032)http://10.133.2.200/ai/lstm.html -->
<html xmlns="http://www.w3.org/1999/xhtml" lang="ja" xml:lang="ja" style="--vsc-domain: &quot;10.133.2.200&quot;;"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<meta name="viewport" content="width=device-width, initial-scale=1">
<title>LSTMと時系列データ処理</title>
<meta name="author" content="Hirotaka Niitsuma">
<meta name="generator" content="Org Mode">
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="./LSTMと時系列データ処理_files/text.css"><script src="./LSTMと時系列データ処理_files/jquery-1.9.1.min.js.ダウンロード"></script>
<style>.ssBtnDefault{position:absolute;z-index:100000000;background:none;border:none;outline:none;right:0;cursor:pointer;width:26px;height:26px;margin:0;padding:0;top:8px;right:8px;opacity:.6;pointer-events:all;transition-duration:.25s}.ssBtnDefault:hover{opacity:1 !important;transition-duration:.25s}.ssBtnDefault .fade{transition-duration:5s;opacity:0}.ssBtnYouTube{background:none;border:none;margin-right:20px !important;padding-top:0px !important;width:25px !important}.ytp-embed .ssBtnYouTube{width:20px !important;margin-right:15px !important}.ssBtnVimeo{height:2rem !important;width:2rem !important;margin-top:8px !important}.ssBtnVimeo button{width:100% !important;height:100% !important}.ssBtnVimeo button svg{width:19px}.ssBtnNetflix{background:none;border:none;cursor:pointer;width:4rem;margin:0 .5rem;display:inline-block;flex-shrink:0}.ssBtnNetflix>svg{transform:translateY(-0.5rem)}.ssBtnNetflix:hover{transform:scale(1.2);transition-duration:.25s}.ssBtnHulu{width:27px;margin-top:4px;margin-right:10px;opacity:.7;cursor:pointer}.ssBtnHulu:hover{opacity:1}.ssBtnAmazon{margin-left:1.5vw;outline:none;cursor:pointer;opacity:.8}.ssBtnAmazon:hover{opacity:1}@media(min-width: 1200px){.ssBtnAmazon{width:1.6666666667vw;height:1.6666666667vw}}@media(max-width: 1199px){.ssBtnAmazon{width:20px;height:20px}}.ssBtnMax{width:24px;height:24px;margin:4px;padding:12px;box-sizing:content-box;position:relative;opacity:.7;cursor:pointer;display:flex;justify-content:center;align-items:center}.ssBtnMax:hover{opacity:1;transform:scale(1.2)}.ssBtnMax svg{width:24px;height:24px}.ssBtnDisney{opacity:.7}.ssBtnDisney:hover{opacity:1}.ssBtnDisney svg{width:25px !important;height:31px !important;padding-top:4px;margin-right:7px}.ssBtnApple{cursor:pointer;opacity:.7}.ssBtnApple:hover{opacity:1}.ssBtnApple svg{width:22px !important;height:22px !important;margin-right:2px !important}body .vsNotification{display:flex;width:100%;height:4rem;justify-content:center;align-items:center;position:fixed;z-index:1000000000;top:-4rem;padding:.75rem 1.25em;border:1px solid rgba(0,0,0,0);border-radius:.25em;font-size:12px;height:fit-content;justify-self:center;width:auto;animation-name:notification;animation-iteration-count:1;animation-duration:2s}@keyframes notification{0%{top:-4rem}25%{top:3rem}85%{top:3rem}100%{top:-4rem}}body .vsNotification.persist{top:3rem;animation-name:notification-persist;animation-iteration-count:1;animation-duration:1s}@keyframes notification-persist{0%{top:-4rem}100%{top:3rem}}body .vsNotification.success{background-color:#d4edda;border-color:#c3e6cb;color:#155724}body .vsNotification.fail{background-color:#edd4d4;border-color:#e6c3c3;color:#b62424}body .vsNotification .vsNotificationClose{color:#b62424;border:none;background-color:rgba(0,0,0,0);padding:0;line-height:0;position:relative;left:.5rem;cursor:pointer}body .vsNotification .vsNContent{position:absolute;z-index:1000000000;margin-bottom:1em;padding:.75rem 1.25em;border:1px solid rgba(0,0,0,0);border-radius:.25em;font-size:12px;height:fit-content;top:0}body .vsNotification a{color:#b62424}.ssModal{display:none;position:fixed;z-index:100000000;right:20px;opacity:0;background-color:#fffefa;border-radius:3px;padding:25px;color:#525252;font-family:muli,sans-serif;box-shadow:0px 4px 8px 0px rgba(0,0,0,.15);animation-name:animateOn;animation-duration:.2s;animation-fill-mode:forwards}.ssModal.visible{display:block}.ssModal *{vertical-align:middle;line-height:normal;font-weight:normal}@keyframes animateOn{from{opacity:0;top:0px}to{opacity:1;top:20px}}.ssModal .close{position:absolute;right:10px;top:10px;cursor:pointer;opacity:.5;background-image:url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDI3LjAuMCwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPgo8c3ZnIHZlcnNpb249IjEuMSIgaWQ9IkxheWVyXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4IgoJIHZpZXdCb3g9IjAgMCA0NDMuNCA0NDMuNCIgc3R5bGU9ImVuYWJsZS1iYWNrZ3JvdW5kOm5ldyAwIDAgNDQzLjQgNDQzLjQ7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4KPHBhdGggZD0iTTYuOCw0MDMuNWwxODEuOC0xODEuOEw2LjgsMzkuOWMtNS45LTUuOS04LjItMTQuNS02LTIyLjZDMyw5LjIsOS4yLDMsMTcuMywwLjhjOC4xLTIuMiwxNi43LDAuMSwyMi42LDZsMTgxLjgsMTgxLjgKCUw0MDMuNSw2LjhjNS45LTUuOSwxNC41LTguMiwyMi42LTZjOC4xLDIuMiwxNC40LDguNCwxNi41LDE2LjVjMi4yLDguMS0wLjEsMTYuNy02LDIyLjZMMjU0LjcsMjIxLjdsMTgxLjgsMTgxLjgKCWM1LjksNS45LDguMiwxNC41LDYsMjIuNmMtMi4yLDguMS04LjQsMTQuNC0xNi41LDE2LjVjLTguMSwyLjItMTYuNy0wLjEtMjIuNi02TDIyMS43LDI1NC43TDM5LjksNDM2LjVjLTUuOSw1LjktMTQuNSw4LjItMjIuNiw2CglDOS4yLDQ0MC40LDMsNDM0LjEsMC44LDQyNkMtMS40LDQxOCwwLjksNDA5LjQsNi44LDQwMy41TDYuOCw0MDMuNXoiLz4KPC9zdmc+Cg==);width:10px;height:10px}.ssModal .ssButtons{margin-top:25px;text-align:right}.ssModal .ssButtons .ssButton,.ssModal .ssButtons a .ssButton{display:inline-block;height:20px;padding:3px 12px 3px;margin-left:14px;border-radius:4px;box-shadow:0px 4px 8px 0px rgba(0,0,0,.15);background-color:#fff;font-size:12px;color:#525252;line-height:20px;font-weight:normal;cursor:pointer;text-decoration:none}.ssModal .ssButtons .ssButton .emoji,.ssModal .ssButtons a .ssButton .emoji{font-size:15px;vertical-align:bottom}.ssModal .ssButtons .ssButton.blue,.ssModal .ssButtons a .ssButton.blue{background-color:#19acef;color:#fff}.ssModal .icon{background-image:url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDI1LjIuMywgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPgo8c3ZnIHZlcnNpb249IjEuMSIKCSBpZD0iTGF5ZXJfMSIgeG1sbnM6Y2M9Imh0dHA6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL25zIyIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIiB4bWxuczppbmtzY2FwZT0iaHR0cDovL3d3dy5pbmtzY2FwZS5vcmcvbmFtZXNwYWNlcy9pbmtzY2FwZSIgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIiB4bWxuczpzb2RpcG9kaT0iaHR0cDovL3NvZGlwb2RpLnNvdXJjZWZvcmdlLm5ldC9EVEQvc29kaXBvZGktMC5kdGQiIHhtbG5zOnN2Zz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciCgkgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeD0iMHB4IiB5PSIwcHgiIHZpZXdCb3g9IjAgMCAxMDAgODMuOSIKCSBzdHlsZT0iZW5hYmxlLWJhY2tncm91bmQ6bmV3IDAgMCAxMDAgODMuOTsiIHhtbDpzcGFjZT0icHJlc2VydmUiPgo8c3R5bGUgdHlwZT0idGV4dC9jc3MiPgoJLnN0MHtmaWxsOiMwMEFERUY7fQo8L3N0eWxlPgo8ZyB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLC05NTIuMzYyMTgpIj4KCTxwYXRoIGNsYXNzPSJzdDAiIGQ9Ik0zNS42LDk1Mi40Yy0xLjMsMC0yLjQsMS0yLjksMS44bC01LjYsMTEuMUgxMWMtNiwwLTExLDUtMTEsMTF2NDljMCw2LDUsMTEsMTEsMTFoNzhjNiwwLDExLTUsMTEtMTF2LTQ5CgkJYzAtNi01LTExLTExLTExSDcyLjlsLTUuNi0xMS4xYy0wLjUtMS4xLTEuNi0xLjgtMi45LTEuOEwzNS42LDk1Mi40TDM1LjYsOTUyLjR6IE0zNy42LDk1OC44aDI1LjJsNS41LDExLjEKCQljMC41LDEuMSwxLjYsMS44LDIuOSwxLjhoMTguMWMyLjYsMCw0LjUsMS45LDQuNSw0LjV2NDljMCwyLjYtMS45LDQuNS00LjUsNC41SDExLjFjLTIuNiwwLTQuNS0xLjktNC41LTQuNXYtNDkKCQljMC0yLjYsMS45LTQuNSw0LjUtNC41aDE4LjFjMS4xLDAsMi40LTAuOCwyLjktMS44TDM3LjYsOTU4Ljh6IE01MC4yLDk3OS44Yy0xMS42LDAtMjEsOS40LTIxLDIxczkuNCwyMSwyMSwyMXMyMS05LjQsMjEtMjEKCQlTNjEuOCw5NzkuOCw1MC4yLDk3OS44eiBNNTAuMiw5ODYuMmM4LjEsMCwxNC41LDYuNSwxNC41LDE0LjVzLTYuNSwxNC41LTE0LjUsMTQuNXMtMTQuNS02LjUtMTQuNS0xNC41UzQyLjEsOTg2LjIsNTAuMiw5ODYuMnoiLz4KPC9nPgo8L3N2Zz4K);background-repeat:no-repeat;width:30px;height:30px;vertical-align:top;margin-right:22px;margin-top:2px;display:inline-block}.ssModal .body{display:inline-block;width:315px}.ssModal .body .title{font-size:15px;font-weight:600;margin-bottom:7px}.ssModal .body .description{font-size:13px;font-weight:lighter}body #ssTempHolder{position:fixed;z-index:1000000000000;width:100%;height:100%;top:0;pointer-events:none}body #ssTempHolder video{width:auto !important;height:auto !important;max-width:100% !important;max-height:100% !important;top:0 !important;left:0 !important;transform:none !important}body.ssTakeScreenshot .ssElement{z-index:100000000000 !important}body.ssTakeScreenshot.ssNetflix [data-uia=video-canvas]{z-index:10000000}body.ssTakeScreenshot.ssNetflix video{background-color:#000}body.ssTakeScreenshot.ssNetflix .player-timedtext{display:none !important}body.ssTakeScreenshot.ssNetflix.showSubs .player-timedtext{display:block !important}body.ssTakeScreenshot.ssAmazon .dv-player-fullscreen video{z-index:99999999 !important}body.ssTakeScreenshot.ssDisney .btm-media-overlays-container{display:none}body.ssTakeScreenshot.ssDisney .TimedTextOverlay{display:none}body.ssTakeScreenshot.ssDisney.showSubs .TimedTextOverlay{display:block}body.ssTakeScreenshot.ssHulu .ContentPlayer__contentArea{z-index:10000000000;position:relative}body.ssTakeScreenshot.ssHulu .ClosedCaption{display:none}body.ssTakeScreenshot.ssHulu.showSubs .ClosedCaption{display:block}body.ssTakeScreenshot.ssMax video{z-index:99999999;position:relative}body.ssTakeScreenshot.ssYoutube .html5-video-container,body.ssTakeScreenshot.ssYoutube .ytp-caption-window-container{z-index:999999999 !important}body.ssTakeScreenshot.ssApple #apple-music-video-player{z-index:999999999 !important}body.ssTakeScreenshot.ssApple .video-player-scrim{display:none}body .ssWrapper{overflow:hidden}
/*# sourceMappingURL=data:application/json;base64,{"version":3,"sources":["webpack://./scss/ScreenshotControl/_buttons.scss","webpack://./scss/ScreenshotControl/_notifications.scss","webpack://./scss/ScreenshotControl/_modal.scss","webpack://./scss/ScreenshotControl.scss"],"names":[],"mappings":"AAAA,cAEC,iBAAA,CACA,iBAAA,CACA,eAAA,CACA,WAAA,CACA,YAAA,CACA,OAAA,CACA,cAAA,CAEA,UAAA,CACA,WAAA,CACA,QAAA,CACA,SAAA,CACA,OAAA,CACA,SAAA,CAEA,UAAA,CACA,kBAAA,CAEG,wBAAA,CAEA,oBACI,oBAAA,CACA,wBAAA,CAGJ,oBACI,sBAAA,CACA,SAAA,CAQR,cAEC,eAAA,CACA,WAAA,CAEA,4BAAA,CACG,0BAAA,CACA,qBAAA,CAEH,yBACC,qBAAA,CACA,4BAAA,CAIF,YAEC,sBAAA,CACG,qBAAA,CAEA,yBAAA,CAEH,mBAEC,qBAAA,CACA,sBAAA,CAEA,uBACC,UAAA,CAMH,cACC,eAAA,CACA,WAAA,CACA,cAAA,CAEA,UAAA,CAEA,cAAA,CAGA,oBAAA,CACA,aAAA,CAUA,kBAEC,6BAAA,CAIE,oBACI,oBAAA,CACH,wBAAA,CAIL,WAEC,UAAA,CACA,cAAA,CACA,iBAAA,CACA,UAAA,CACA,cAAA,CAEA,iBACC,SAAA,CAIF,aACC,iBAAA,CAEA,YAAA,CAEG,cAAA,CACA,UAAA,CAIA,mBACI,SAAA,CAIR,0BAAA,aAAA,oBAAA,CAAA,qBAAA,CAAA,CACA,0BAAA,aAAA,UAAA,CAAA,WAAA,CAAA,CAGA,UAEI,UAAA,CACA,WAAA,CACH,UAAA,CACA,YAAA,CACA,sBAAA,CAEG,iBAAA,CACA,UAAA,CACA,cAAA,CACA,YAAA,CACA,sBAAA,CACA,kBAAA,CAEH,gBACC,SAAA,CACA,oBAAA,CAGD,cACC,UAAA,CACA,WAAA,CAIF,aAGI,UAAA,CAEH,mBACC,SAAA,CAGD,iBACC,qBAAA,CACA,sBAAA,CACA,eAAA,CACA,gBAAA,CAIF,YAIC,cAAA,CAGG,UAAA,CAEH,kBACC,SAAA,CAGD,gBACC,qBAAA,CACA,sBAAA,CACA,2BAAA,CCnMF,qBAEI,YAAA,CACA,UAAA,CACA,WAAA,CACA,sBAAA,CACA,kBAAA,CACA,cAAA,CACA,kBAAA,CACA,SAAA,CAEA,qBAAA,CACA,8BAAA,CACA,mBAAA,CACA,cAAA,CACA,kBAAA,CACA,mBAAA,CACA,UAAA,CAEA,2BAAA,CACA,2BAAA,CACA,qBAAA,CAEA,wBACI,GAAA,SAAA,CACA,IAAA,QAAA,CACA,IAAA,QAAA,CACA,KAAA,SAAA,CAAA,CAGJ,6BAGI,QAAA,CAEA,mCAAA,CACA,2BAAA,CACA,qBAAA,CAEA,gCACI,GAAA,SAAA,CACA,KAAA,QAAA,CAAA,CAKR,6BACI,wBAAA,CACA,oBAAA,CACA,aAAA,CAGJ,0BACI,wBAAA,CACA,oBAAA,CACA,aAAA,CAGJ,0CACI,aAAA,CACA,WAAA,CACA,8BAAA,CACA,SAAA,CACA,aAAA,CACA,iBAAA,CACA,UAAA,CACA,cAAA,CAGJ,iCAEI,iBAAA,CACA,kBAAA,CACA,iBAAA,CACA,qBAAA,CACA,8BAAA,CACA,mBAAA,CACA,cAAA,CACA,kBAAA,CACA,KAAA,CAGJ,uBACI,aAAA,CCnFR,SAEI,YAAA,CAMA,cAAA,CACA,iBAAA,CAEA,UAAA,CAEA,SAAA,CAEA,wBAAA,CACA,iBAAA,CAEA,YAAA,CAEA,aAAA,CACA,2BAAA,CAEA,0CAAA,CAEA,wBAAA,CACA,sBAAA,CACA,4BAAA,CAvBA,iBACI,aAAA,CAwBJ,WACI,qBAAA,CACA,kBAAA,CACA,kBAAA,CAGJ,qBACI,KACI,SAAA,CACA,OAAA,CAEJ,GACI,SAAA,CACA,QAAA,CAAA,CAIR,gBACI,iBAAA,CACA,UAAA,CACA,QAAA,CACA,cAAA,CACA,UAAA,CAEA,wDAAA,CAEA,UAAA,CACA,WAAA,CAIJ,oBAEI,eAAA,CACA,gBAAA,CAEA,8DACI,oBAAA,CAEA,WAAA,CAEA,oBAAA,CACA,gBAAA,CAEA,iBAAA,CACA,0CAAA,CACA,qBAAA,CAEA,cAAA,CACA,aAAA,CACA,gBAAA,CACA,kBAAA,CAEA,cAAA,CAEA,oBAAA,CAEA,4EACI,cAAA,CACA,qBAAA,CAGJ,wEACI,wBAAA,CACA,UAAA,CAKZ,eACI,wDAAA,CACA,2BAAA,CAEA,UAAA,CACA,WAAA,CAEA,kBAAA,CACA,iBAAA,CACA,cAAA,CAEA,oBAAA,CAGJ,eAEI,oBAAA,CACA,WAAA,CAEA,sBACI,cAAA,CACA,eAAA,CACA,iBAAA,CAEJ,4BACI,cAAA,CACA,mBAAA,CCrHX,mBACC,cAAA,CACA,qBAAA,CACA,UAAA,CACA,WAAA,CACA,KAAA,CACA,mBAAA,CAEA,yBACC,qBAAA,CACA,sBAAA,CACA,yBAAA,CACA,0BAAA,CACA,gBAAA,CACA,iBAAA,CACA,yBAAA,CAMD,iCACC,+BAAA,CAKA,wDACC,gBAAA,CAGD,sCACC,qBAAA,CAID,kDAEC,uBAAA,CAKA,2DAEC,wBAAA,CAQF,2DACC,2BAAA,CAMD,6DACC,YAAA,CAGD,iDACC,YAAA,CAKA,0DACC,aAAA,CAMF,yDACC,mBAAA,CACG,iBAAA,CAGJ,4CACC,YAAA,CAIA,qDACC,aAAA,CAOF,kCACC,gBAAA,CACA,iBAAA,CAcD,qHACC,4BAAA,CAKD,wDACC,4BAAA,CAGD,kDACC,YAAA,CAKH,gBACC,eAAA","sourcesContent":[".ssBtnDefault {\n\t\n\tposition: absolute;\n\tz-index: 100000000;\n\tbackground:none;\n\tborder: none;\n\toutline: none;\n\tright:0;\n\tcursor: pointer;\n\t\n\twidth: 26px;\n\theight: 26px;\n\tmargin: 0;//5% 8px 0;\n\tpadding:0;\n\ttop:8px;\n\tright:8px;\n\t\n\topacity: .6;\n\tpointer-events: all;\n\t/*transition-fill-mode: forwards;*/\n    transition-duration: .25s;\n\n    &:hover {\n        opacity: 1 !important; \n        transition-duration: .25s;\n    }\n\n    .fade {\n        transition-duration: 5s;\n        opacity: 0;\n    }\n    \n    /*svg {\n        background-color:red;\n    }*/\n}\n\n.ssBtnYouTube {\n\n\tbackground:none;\n\tborder: none;\n\t\n\tmargin-right: 20px !important;\n    padding-top: 0px !important;\n    width: 25px !important;\n\n\t.ytp-embed & {\n\t\twidth: 20px !important;\n\t\tmargin-right: 15px !important;\n\t}\n}\n\n.ssBtnVimeo {\n\n\theight: 2rem !important;\n    width: 2rem !important;\n    //padding: 6px !important;\n    margin-top: 8px !important;\n\n\tbutton {\n\n\t\twidth: 100% !important;\n\t\theight: 100% !important;\n\t\t\n\t\tsvg {\n\t\t\twidth: 19px;\n\t\t}\n\t}\n\n}\n\n.ssBtnNetflix {\n\tbackground:none;\n\tborder: none;\n\tcursor: pointer;\n\n\twidth:4rem;\n\t\n\tmargin: 0 0.5rem;\n\t//margin: 0 2rem 0 4rem;\n\n\tdisplay:inline-block;\n\tflex-shrink: 0;\n\t\n\t//margin-top:-1rem;\n\t//height:2.4rem;\n\t//width: 50px;\n\t//height: 35px !important;\n\t//width: 100%;//3.6em !important;\n    //height: 100%;//1.6em !important;\n\t//padding:0 0 .6em 0;\n\n\t& > svg {\n\t\t//margin-top:-.3rem;\n\t\ttransform:translateY(-.5rem);\n\t\t//transform: scale(.5);\n\t}\n    \n    &:hover {\n        transform:scale(1.2);\n\t    transition-duration: .25s;\n    }\n}\n\n.ssBtnHulu {\n\t\n\twidth: 27px;\n\tmargin-top: 4px;\n\tmargin-right:10px;\n\topacity: .7;\n\tcursor: pointer;\n\t\n\t&:hover {\n\t\topacity: 1;\n\t}\n}\n\n.ssBtnAmazon {\n\tmargin-left: 1.5vw;\n    \n\toutline: none;\n\t\n   \tcursor: pointer;\n   \topacity: .8;\n\n   \t//z-index: 9999999999;\n\n    &:hover {\n        opacity: 1;\n    }\n}\n\n@media (min-width: 1200px) { .ssBtnAmazon { width: 1.6666666666666665vw; height: 1.6666666666666665vw; } }\n@media (max-width: 1199px) { .ssBtnAmazon { width: 20px; height: 20px; } }\n\n\n.ssBtnMax {\n\n    width: 24px;\n    height: 24px;\n\tmargin: 4px;\n\tpadding:12px;\n\tbox-sizing: content-box;\n\n    position: relative;\n    opacity: 0.7;\n    cursor: pointer;\n    display: flex;\n    justify-content: center;\n    align-items: center;\n\n\t&:hover {\n\t\topacity: 1;\n\t\ttransform: scale(1.2);\n\t}\n\n\tsvg {\n\t\twidth: 24px;\n\t\theight: 24px;\n\t}\n}\n\n.ssBtnDisney {\n\t//width: 26px;\n    //margin-right: 13px;\n    opacity: .7;\n\n\t&:hover {\n\t\topacity: 1;\n\t}\n\n\tsvg {\n\t\twidth: 25px !important;\n\t\theight: 31px !important;\n\t\tpadding-top: 4px;\n\t\tmargin-right: 7px;\n\t}\n}\n\n.ssBtnApple {\n\t//width: 26px;\n    //margin-right: 13px;\n\n\tcursor: pointer;\n\n\n    opacity: .7;\n\n\t&:hover {\n\t\topacity: 1;\n\t}\n\n\tsvg {\n\t\twidth: 22px !important;\n\t\theight: 22px !important;\n\t\tmargin-right: 2px !important;\n\t}\n}","body .vsNotification {\n\n    display: flex;\n    width: 100%;\n    height: 4rem;\n    justify-content: center;\n    align-items: center;\n    position: fixed;\n    z-index: 1000000000;\n    top:-4rem;\n\n    padding: .75rem 1.25em;\n    border: 1px solid transparent;\n    border-radius: .25em;\n    font-size: 12px;\n    height: fit-content;\n    justify-self: center;\n    width: auto;\n\n    animation-name: notification;\n    animation-iteration-count: 1;\n    animation-duration: 2s;\n\n    @keyframes notification {\n        0% {top: -4rem;}\n        25% {top: 3rem;}\n        85% {top: 3rem;}\n        100% {top: -4rem;}\n    }\n\n    &.persist {\n        //don't reset animation or go back to beginning\n\n        top: 3rem;\n\n        animation-name: notification-persist;\n        animation-iteration-count: 1;\n        animation-duration: 1s;\n\n        @keyframes notification-persist {\n            0% {top: -4rem;}\n            100% {top: 3rem;}\n        }\n    }\n\n\n    &.success {\n        background-color: #d4edda;\n        border-color: #c3e6cb;\n        color: #155724;\n    }\n\n    &.fail {\n        background-color: #edd4d4;\n        border-color: #e6c3c3;\n        color: #b62424;\n    }\n\n    .vsNotificationClose {\n        color: #b62424;\n        border: none;\n        background-color: transparent;\n        padding: 0;\n        line-height: 0;\n        position: relative;\n        left: .5rem;\n        cursor: pointer;\n    }\n\n    .vsNContent {\n        //content: 'Screenshot copied to clipboard!';\n        position: absolute;\n        z-index: 1000000000;\n        margin-bottom: 1em;\n        padding: .75rem 1.25em;\n        border: 1px solid transparent;\n        border-radius: .25em;\n        font-size: 12px;\n        height: fit-content;\n        top:0;\n    }\n\n    a {\n        color:#b62424;\n    }\n\n}",".ssModal {\n\n    display: none;\n\n    &.visible {\n        display:block;\n    }\n\n    position: fixed;\n    z-index: 100000000;\n\n    right:20px;\n    \n    opacity: 0;\n\n    background-color:#fffefa;\n    border-radius: 3px;\n\n    padding: 25px;\n\n    color: #525252;\n    font-family: muli, sans-serif;\n\n    box-shadow: 0px 4px 8px 0px rgba(0, 0, 0, 0.15);\n\n    animation-name: animateOn;\n    animation-duration: .2s;\n    animation-fill-mode: forwards;\n    \n    * {\n        vertical-align: middle;\n        line-height: normal;\n        font-weight: normal;\n    }\n\n    @keyframes animateOn {\n        from {\n            opacity: 0;\n            top: 0px;\n        }\n        to {\n            opacity: 1;\n            top: 20px;\n        }\n    }\n\n    .close {\n        position: absolute;\n        right: 10px;\n        top: 10px;\n        cursor: pointer;\n        opacity: .5;\n\n        background-image: url('../images/close.svg');\n\n        width:10px;\n        height:10px;\n\n    }\n\n    .ssButtons {\n\n        margin-top: 25px;\n        text-align: right;\n\n        .ssButton, a .ssButton {\n            display:inline-block;\n\n            height:20px;\n            \n            padding:3px 12px 3px;\n            margin-left: 14px;\n            \n            border-radius: 4px;\n            box-shadow: 0px 4px 8px 0px rgba(0, 0, 0, 0.15);\n            background-color: #FFFFFF;\n            \n            font-size: 12px;\n            color: #525252;\n            line-height: 20px;\n            font-weight: normal;\n    \n            cursor: pointer;\n\n            text-decoration: none;\n\n            .emoji {\n                font-size: 15px;\n                vertical-align: bottom;\n            }\n    \n            &.blue {\n                background-color: #19acef;\n                color: #FFFFFF;\n            }\n        }\n    }\n\n    .icon {\n        background-image: url('../images/iconBlue.svg');\n        background-repeat: no-repeat;\n\n        width:30px;\n        height:30px;\n\n        vertical-align: top;\n        margin-right: 22px;\n        margin-top:2px;\n\n        display:inline-block;\n    }\n\n    .body {\n\n        display:inline-block;\n        width:315px;\n\n        .title {\n            font-size: 15px;\n            font-weight: 600;\n            margin-bottom: 7px;\n        }\n        .description {\n            font-size: 13px;\n            font-weight: lighter;\n        }\n    }\n\n}","@use \"ScreenshotControl/buttons\";\n\n@use \"ScreenshotControl/notifications\";\n@use \"ScreenshotControl/modal\";\n\nbody {\n\n\t#ssTempHolder {\n\t\tposition:fixed;\n\t\tz-index:1000000000000;\n\t\twidth:100%;\n\t\theight:100%;\n\t\ttop:0;\n\t\tpointer-events: none;\n\n\t\tvideo {\n\t\t\twidth:auto !important;\n\t\t\theight:auto !important;\n\t\t\tmax-width:100% !important;\n\t\t\tmax-height: 100% !important;\n\t\t\ttop: 0 !important;\n\t\t\tleft: 0 !important;\n\t\t\ttransform: none !important;\n\t\t}\n\t}\n\n\t&.ssTakeScreenshot {\n\t\t\n\t\t.ssElement {\n\t\t\tz-index: 100000000000 !important;\n\t\t}\n\t\t\n\t\t&.ssNetflix {\n\t\n\t\t\t[data-uia=video-canvas] {\n\t\t\t\tz-index: 10000000;\n\t\t\t}\n\t\t\t\n\t\t\tvideo {\n\t\t\t\tbackground-color: #000000;\n\t\t\t\t//height: auto !important;\n\t\t\t}\n\n\t\t\t.player-timedtext {\n\n\t\t\t\tdisplay:none !important;\n\t\t\t}\t\t\t\n\n\t\t\t&.showSubs {\n\t\t\t\t\n\t\t\t\t.player-timedtext {\n\n\t\t\t\t\tdisplay: block !important;\n\t\t\t\t\t//bottom: 10% !important;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t&.ssAmazon {\n\n\t\t\t.dv-player-fullscreen video {\n\t\t\t\tz-index: 99999999 !important;\n\t\t\t}\n\t\t}\n\n\t\t&.ssDisney {\n\n\t\t\t.btm-media-overlays-container {\n\t\t\t\tdisplay:none;\n\t\t\t}\n\n\t\t\t.TimedTextOverlay {\n\t\t\t\tdisplay: none;\n\t\t\t}\n\n\t\t\t&.showSubs {\n\t\t\t\t\n\t\t\t\t.TimedTextOverlay {\n\t\t\t\t\tdisplay: block;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t&.ssHulu {\n\t\t\t.ContentPlayer__contentArea {\n\t\t\t\tz-index: 10000000000;\n    \t\t\tposition: relative;\n\t\t\t}\n\n\t\t\t.ClosedCaption {\n\t\t\t\tdisplay:none;\n\t\t\t}\n\n\t\t\t&.showSubs {\n\t\t\t\t.ClosedCaption {\n\t\t\t\t\tdisplay:block;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t&.ssMax {\n\n\t\t\tvideo {\n\t\t\t\tz-index: 99999999;\n\t\t\t\tposition: relative;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t//don't know what this is for\n\t\t\t*:has(video) {\n\t\t\t\tz-index: 99999999;\n\t\t\t\tposition: relative;\n\t\t\t}*/\n\n\t\t}\n\n\t\t&.ssYoutube {\n\n\t\t\t.html5-video-container, .ytp-caption-window-container {\n\t\t\t\tz-index: 999999999 !important;\n\t\t\t}\n\t\t}\n\n\t\t&.ssApple {\n\t\t\t#apple-music-video-player {\n\t\t\t\tz-index: 999999999 !important;\n\t\t\t}\n\n\t\t\t.video-player-scrim {\n\t\t\t\tdisplay:none;\n\t\t\t}\n\t\t}\n\t}\n\n\t.ssWrapper {\n\t\toverflow: hidden;\n\t}\n\n\n}"],"sourceRoot":""} */</style></head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href="http://10.133.2.200/ai/index.html"> UP </a>
 |
 <a accesskey="H" href="http://10.133.2.200/ai/index.html"> HOME </a>
</div><div id="content" class="content">
<h1 class="title">LSTMと時系列データ処理</h1>
<div id="table-of-contents" role="doc-toc">
<h2>目次</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="http://10.133.2.200/ai/lstm.html#org7c2caf4">1. python基本文法</a></li>
<li><a href="http://10.133.2.200/ai/lstm.html#orgafb3603">2. sin関数をニューラルネットに学習させてみる</a></li>
<li><a href="http://10.133.2.200/ai/lstm.html#org2829a66">3. googleトレンドをニューラルネットに学習させてみる</a></li>
<li><a href="http://10.133.2.200/ai/lstm.html#orgd86ffde">4. 演習</a></li>
<li><a href="http://10.133.2.200/ai/lstm.html#org81947fe">5. 課題</a></li>
</ul>
</div>
</div>

<div id="outline-container-org7c2caf4" class="outline-2">
<h2 id="org7c2caf4"><span class="section-number-2">1.</span> python基本文法</h2>
<div class="outline-text-2" id="text-1">
<p>
時系列データの多くはpandasというライブラリを使って扱われる
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span># pip3 install pandas
<span class="linenr"> 2: </span>import pandas as pd
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span># 辞書からDataFrameを作成
<span class="linenr"> 5: </span>data = {
<span class="linenr"> 6: </span>    "名前": ["Alice", "Bob", "Charlie", "David"],
<span class="linenr"> 7: </span>    "年齢": [24, 30, 18, 35],
<span class="linenr"> 8: </span>    "点数": [85, 92, 78, 88]
<span class="linenr"> 9: </span>}
<span class="linenr">10: </span>
<span class="linenr">11: </span>df = pd.DataFrame(data)
<span class="linenr">12: </span>print(df)
<span class="linenr">13: </span>
<span class="linenr">14: </span>#      名前  年齢  点数
<span class="linenr">15: </span>#0   Alice  24  85
<span class="linenr">16: </span>#1     Bob  30  92
<span class="linenr">17: </span>#2  Charlie  18  78
<span class="linenr">18: </span>#3   David  35  88
</pre>
</div>


<p>
sin波をpandasのデータとして格納
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>import numpy as np
<span class="linenr"> 2: </span>import pandas as pd
<span class="linenr"> 3: </span>time = np.arange(0, 200, 0.1)
<span class="linenr"> 4: </span>data = np.sin(time) + 0.1 * np.random.randn(len(time))  # sin波+ノイズ
<span class="linenr"> 5: </span>
<span class="linenr"> 6: </span>df = pd.DataFrame({"time": time, "value": data})
<span class="linenr"> 7: </span>df.set_index("time", inplace=True)
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span>import matplotlib.pyplot as plt
<span class="linenr">10: </span>df.plot()
<span class="linenr">11: </span>plt.show()
</pre>
</div>
</div>
</div>



<div id="outline-container-orgafb3603" class="outline-2">
<h2 id="orgafb3603"><span class="section-number-2">2.</span> sin関数をニューラルネットに学習させてみる</h2>
<div class="outline-text-2" id="text-2">
<p>
<a href="http://10.133.2.200/ai/dyn/examples/lstmsin.py">dyn/examples/lstmsin.py</a>
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>import numpy as np
<span class="linenr"> 2: </span>import pandas as pd
<span class="linenr"> 3: </span>import torch
<span class="linenr"> 4: </span>import torch.nn as nn
<span class="linenr"> 5: </span>from torch.utils.data import Dataset, DataLoader
<span class="linenr"> 6: </span>import matplotlib.pyplot as plt
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span># ==== 1. ダミー時系列データを作る（sin波） ====
<span class="linenr"> 9: </span>np.random.seed(0)
<span class="linenr">10: </span>time = np.arange(0, 200, 0.1)
<span class="linenr">11: </span>data = np.sin(time) + 0.1 * np.random.randn(len(time))  # sin波+ノイズ
<span class="linenr">12: </span>
<span class="linenr">13: </span>df = pd.DataFrame({"time": time, "value": data})
<span class="linenr">14: </span>df.set_index("time", inplace=True)
<span class="linenr">15: </span>
<span class="linenr">16: </span># ==== 2. 学習・テスト分割 ====
<span class="linenr">17: </span>train_size = int(len(df) * 0.8)
<span class="linenr">18: </span>train_series = df.iloc[:train_size]["value"]
<span class="linenr">19: </span>test_series = df.iloc[train_size:]["value"]
<span class="linenr">20: </span>
<span class="linenr">21: </span>SEQ_LEN = 20 ##この変数の意味？
<span class="linenr">22: </span>
<span class="linenr">23: </span>class TimeSeriesDataset(Dataset):
<span class="linenr">24: </span>    def __init__(self, series, seq_len=20):
<span class="linenr">25: </span>        self.series = torch.tensor(series.values, dtype=torch.float32)
<span class="linenr">26: </span>        self.seq_len = seq_len
<span class="linenr">27: </span>
<span class="linenr">28: </span>    def __len__(self):
<span class="linenr">29: </span>        return len(self.series) - self.seq_len
<span class="linenr">30: </span>
<span class="linenr">31: </span>    def __getitem__(self, idx):
<span class="linenr">32: </span>        x = self.series[idx:idx+self.seq_len].unsqueeze(-1)  # (seq_len,1)
<span class="linenr">33: </span>        y = self.series[idx+self.seq_len]
<span class="linenr">34: </span>        return x, y
<span class="linenr">35: </span>
<span class="linenr">36: </span>train_dataset = TimeSeriesDataset(train_series, SEQ_LEN)
<span class="linenr">37: </span>test_dataset = TimeSeriesDataset(test_series, SEQ_LEN)
<span class="linenr">38: </span>
<span class="linenr">39: </span>train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
<span class="linenr">40: </span>
<span class="linenr">41: </span># ==== 3. LSTMモデル定義 ====
<span class="linenr">42: </span>class LSTMModel(nn.Module):
<span class="linenr">43: </span>    def __init__(self, input_size=1, hidden_size=50, num_layers=1):
<span class="linenr">44: </span>        super().__init__()
<span class="linenr">45: </span>        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,
<span class="linenr">46: </span>                            batch_first=True ###ここに注意
<span class="linenr">47: </span>                            )
<span class="linenr">48: </span>        self.fc = nn.Linear(hidden_size, 1)  ###ここの意味は？
<span class="linenr">49: </span>
<span class="linenr">50: </span>    def forward(self, x):
<span class="linenr">51: </span>        out, _ = self.lstm(x)
<span class="linenr">52: </span>        out = out[:, -1, :]   # 最後の時点だけ出力する
<span class="linenr">53: </span>        out = self.fc(out)
<span class="linenr">54: </span>        return out.squeeze()
<span class="linenr">55: </span>
<span class="linenr">56: </span>model = LSTMModel()
<span class="linenr">57: </span>criterion = nn.MSELoss()
<span class="linenr">58: </span>optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
<span class="linenr">59: </span>
<span class="linenr">60: </span># ==== 4. 学習 ====
<span class="linenr">61: </span>EPOCHS = 10
<span class="linenr">62: </span>for epoch in range(EPOCHS):
<span class="linenr">63: </span>    for x, y in train_loader:
<span class="linenr">64: </span>        optimizer.zero_grad()
<span class="linenr">65: </span>        pred = model(x)
<span class="linenr">66: </span>        loss = criterion(pred, y)
<span class="linenr">67: </span>        loss.backward()
<span class="linenr">68: </span>        optimizer.step()
<span class="linenr">69: </span>    print(f"Epoch {epoch+1}/{EPOCHS}, Loss: {loss.item():.4f}")
<span class="linenr">70: </span>
<span class="linenr">71: </span># ==== 5. テストデータで予測 ====
<span class="linenr">72: </span>model.eval() #ここも注意
<span class="linenr">73: </span>preds = []
<span class="linenr">74: </span>with torch.no_grad(): #ここも注意
<span class="linenr">75: </span>    for i in range(len(test_dataset)):
<span class="linenr">76: </span>        x, _ = test_dataset[i]
<span class="linenr">77: </span>        x = x.unsqueeze(0)  # (1, seq_len, 1)
<span class="linenr">78: </span>        pred = model(x).item()
<span class="linenr">79: </span>        preds.append(pred)
<span class="linenr">80: </span>
<span class="linenr">81: </span># ==== 6. グラフ表示 ====
<span class="linenr">82: </span>plt.figure(figsize=(12,6))
<span class="linenr">83: </span>plt.plot(test_series.index[SEQ_LEN:], test_series.values[SEQ_LEN:], label="True", color="blue")
<span class="linenr">84: </span>plt.plot(test_series.index[SEQ_LEN:], preds, label="Predicted", color="red")
<span class="linenr">85: </span>plt.title("LSTM Prediction vs True values")
<span class="linenr">86: </span>plt.xlabel("Time")
<span class="linenr">87: </span>plt.ylabel("Value")
<span class="linenr">88: </span>plt.legend()
<span class="linenr">89: </span>plt.show()
</pre>
</div>


<p>
<a href="https://ja.wikipedia.org/wiki/%E9%95%B7%E3%83%BB%E7%9F%AD%E6%9C%9F%E8%A8%98%E6%86%B6">LSTMとは</a>
</p>

<p>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.LSTM.html">LSTMのpytochのドキュメント)</a>
</p>
</div>
</div>


<div id="outline-container-org2829a66" class="outline-2">
<h2 id="org2829a66"><span class="section-number-2">3.</span> googleトレンドをニューラルネットに学習させてみる</h2>
<div class="outline-text-2" id="text-3">
<p>
以下はBitcoinという単語のgoogleトレンドをニューラルネットに学生させる例
</p>


<p>
<a href="http://10.133.2.200/ai/dyn/examples/lstmtrand.py">dyn/examples/lstmtrand.py</a>
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">  1: </span># =========================
<span class="linenr">  2: </span># 1) ライブラリ
<span class="linenr">  3: </span># =========================
<span class="linenr">  4: </span># pip install pytrends torch matplotlib pandas scikit-learn
<span class="linenr">  5: </span>from pytrends.request import TrendReq
<span class="linenr">  6: </span>import pandas as pd
<span class="linenr">  7: </span>import numpy as np
<span class="linenr">  8: </span>import matplotlib.pyplot as plt
<span class="linenr">  9: </span>
<span class="linenr"> 10: </span>import torch
<span class="linenr"> 11: </span>import torch.nn as nn
<span class="linenr"> 12: </span>from torch.utils.data import Dataset, DataLoader
<span class="linenr"> 13: </span>from sklearn.preprocessing import StandardScaler
<span class="linenr"> 14: </span>
<span class="linenr"> 15: </span># =========================
<span class="linenr"> 16: </span># 2) Googleトレンドからデータ取得
<span class="linenr"> 17: </span># =========================
<span class="linenr"> 18: </span>KEYWORD = "Bitcoin"          # ←好きな単語に変更（日本語OK）
<span class="linenr"> 19: </span>GEO = "JP"                   # 地域（"JP","US",""=全世界 など）
<span class="linenr"> 20: </span>TIMEFRAME = "today 5-y"      # 期間（例: "today 12-m", "today 5-y", "2019-01-01 2025-10-01"）
<span class="linenr"> 21: </span>
<span class="linenr"> 22: </span>pytrends = TrendReq(hl='ja-JP', tz=540)  # 日本時間
<span class="linenr"> 23: </span>pytrends.build_payload([KEYWORD], timeframe=TIMEFRAME, geo=GEO)
<span class="linenr"> 24: </span>df_trend = pytrends.interest_over_time()
<span class="linenr"> 25: </span>
<span class="linenr"> 26: </span># 取得結果の整形
<span class="linenr"> 27: </span>if df_trend.empty:
<span class="linenr"> 28: </span>    raise ValueError("Googleトレンドからデータが取得できませんでした。キーワード/期間/地域を見直してください。")
<span class="linenr"> 29: </span>
<span class="linenr"> 30: </span># isPartial列を削除して、欠損を前方埋め
<span class="linenr"> 31: </span>series = df_trend[KEYWORD].copy()
<span class="linenr"> 32: </span>series = series.asfreq(series.index.inferred_freq) if series.index.inferred_freq else series
<span class="linenr"> 33: </span>series = series.fillna(method="ffill")
<span class="linenr"> 34: </span>series.name = "value"
<span class="linenr"> 35: </span>
<span class="linenr"> 36: </span># =========================
<span class="linenr"> 37: </span># 3) 前処理（標準化＆学習/テスト分割）
<span class="linenr"> 38: </span># =========================
<span class="linenr"> 39: </span># 学習80% / テスト20%
<span class="linenr"> 40: </span>n = len(series)
<span class="linenr"> 41: </span>train_size = int(n * 0.8)
<span class="linenr"> 42: </span>train_idx_end = train_size
<span class="linenr"> 43: </span>
<span class="linenr"> 44: </span>train_series = series.iloc[:train_idx_end]
<span class="linenr"> 45: </span>test_series  = series.iloc[train_idx_end:]
<span class="linenr"> 46: </span>
<span class="linenr"> 47: </span># 標準化（学習データでfit → 両方にtransform）
<span class="linenr"> 48: </span>scaler = StandardScaler()
<span class="linenr"> 49: </span>train_vals = scaler.fit_transform(train_series.values.reshape(-1, 1)).flatten()
<span class="linenr"> 50: </span>test_vals  = scaler.transform(test_series.values.reshape(-1, 1)).flatten()
<span class="linenr"> 51: </span>
<span class="linenr"> 52: </span># =========================
<span class="linenr"> 53: </span># 4) PyTorch Dataset
<span class="linenr"> 54: </span># =========================
<span class="linenr"> 55: </span>SEQ_LEN = 24  # 1ステップ予測用の履歴長（週次なら~半年、日次なら約1ヶ月）
<span class="linenr"> 56: </span>
<span class="linenr"> 57: </span>#### 以前に使ったTimeSeriesDataset(Dataset)との違いに注目(やっていることはほぼ同じだけど、もし後で拡張しようとすると)
<span class="linenr"> 58: </span>class SeqDataset(Dataset):
<span class="linenr"> 59: </span>    def __init__(self, arr, seq_len=24):
<span class="linenr"> 60: </span>        self.x = []
<span class="linenr"> 61: </span>        self.y = []
<span class="linenr"> 62: </span>        for i in range(len(arr) - seq_len):
<span class="linenr"> 63: </span>            self.x.append(arr[i:i+seq_len])
<span class="linenr"> 64: </span>            self.y.append(arr[i+seq_len])
<span class="linenr"> 65: </span>        self.x = torch.tensor(np.array(self.x), dtype=torch.float32).unsqueeze(-1) # (N, seq_len, 1)
<span class="linenr"> 66: </span>        self.y = torch.tensor(np.array(self.y), dtype=torch.float32)               # (N,)
<span class="linenr"> 67: </span>
<span class="linenr"> 68: </span>    def __len__(self):
<span class="linenr"> 69: </span>        return len(self.y)
<span class="linenr"> 70: </span>
<span class="linenr"> 71: </span>    def __getitem__(self, idx):
<span class="linenr"> 72: </span>        return self.x[idx], self.y[idx]
<span class="linenr"> 73: </span>
<span class="linenr"> 74: </span>train_ds = SeqDataset(train_vals, SEQ_LEN)
<span class="linenr"> 75: </span>test_ds  = SeqDataset(test_vals,  SEQ_LEN)
<span class="linenr"> 76: </span>
<span class="linenr"> 77: </span>train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)
<span class="linenr"> 78: </span>
<span class="linenr"> 79: </span>##ここは以前と同じ
<span class="linenr"> 80: </span>class LSTMModel(nn.Module): 
<span class="linenr"> 81: </span>    def __init__(self, input_size=1, hidden_size=50, num_layers=1):
<span class="linenr"> 82: </span>        super().__init__()
<span class="linenr"> 83: </span>        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,
<span class="linenr"> 84: </span>                            batch_first=True ###ここに注意
<span class="linenr"> 85: </span>                            )
<span class="linenr"> 86: </span>        self.fc = nn.Linear(hidden_size, 1)  ###ここの意味は？
<span class="linenr"> 87: </span>    def forward(self, x):
<span class="linenr"> 88: </span>        out, _ = self.lstm(x)  # (B, T, H)
<span class="linenr"> 89: </span>        out = out[:, -1, :]   # 最後の時点だけ出力する
<span class="linenr"> 90: </span>        out = self.fc(out)   # (B, 1)
<span class="linenr"> 91: </span>        return out.squeeze() # (B,)
<span class="linenr"> 92: </span>
<span class="linenr"> 93: </span>
<span class="linenr"> 94: </span>
<span class="linenr"> 95: </span>device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
<span class="linenr"> 96: </span>model = LSTMModel(hidden_size=64, num_layers=1).to(device)
<span class="linenr"> 97: </span>
<span class="linenr"> 98: </span>criterion = nn.MSELoss()
<span class="linenr"> 99: </span>optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
<span class="linenr">100: </span>
<span class="linenr">101: </span># =========================
<span class="linenr">102: </span># 6) 学習
<span class="linenr">103: </span># =========================
<span class="linenr">104: </span>EPOCHS = 15
<span class="linenr">105: </span>model.train()
<span class="linenr">106: </span>for epoch in range(EPOCHS):
<span class="linenr">107: </span>    epoch_loss = 0.0
<span class="linenr">108: </span>    for x, y in train_loader:
<span class="linenr">109: </span>        x = x.to(device)
<span class="linenr">110: </span>        y = y.to(device)
<span class="linenr">111: </span>
<span class="linenr">112: </span>        optimizer.zero_grad()
<span class="linenr">113: </span>        pred = model(x)
<span class="linenr">114: </span>        loss = criterion(pred, y)
<span class="linenr">115: </span>        loss.backward()
<span class="linenr">116: </span>        optimizer.step()
<span class="linenr">117: </span>        epoch_loss += loss.item() * x.size(0)
<span class="linenr">118: </span>
<span class="linenr">119: </span>    print(f"Epoch {epoch+1}/{EPOCHS}  loss={epoch_loss/len(train_ds):.4f}")
<span class="linenr">120: </span>
<span class="linenr">121: </span># =========================
<span class="linenr">122: </span># 7) テストデータで 1ステップ予測
<span class="linenr">123: </span># =========================
<span class="linenr">124: </span>model.eval()
<span class="linenr">125: </span>pred_scaled = []
<span class="linenr">126: </span>with torch.no_grad():
<span class="linenr">127: </span>    for i in range(len(test_ds)):
<span class="linenr">128: </span>        x, _ = test_ds[i]
<span class="linenr">129: </span>        x = x.unsqueeze(0).to(device)  # (1, T, 1)
<span class="linenr">130: </span>        yhat = model(x).cpu().item()
<span class="linenr">131: </span>        pred_scaled.append(yhat)
<span class="linenr">132: </span>
<span class="linenr">133: </span># 逆標準化（スカラーに対して inverse_transform を使えるように2次元化）
<span class="linenr">134: </span>pred_scaled_arr = np.array(pred_scaled).reshape(-1, 1)
<span class="linenr">135: </span>pred_inv = scaler.inverse_transform(pred_scaled_arr).flatten()
<span class="linenr">136: </span>
<span class="linenr">137: </span># 真値（テスト部分のうち、SEQ_LEN 以降が予測対象）
<span class="linenr">138: </span>true_inv = test_series.values[SEQ_LEN:]
<span class="linenr">139: </span>
<span class="linenr">140: </span># 対応するインデックス
<span class="linenr">141: </span>plot_index = test_series.index[SEQ_LEN:]
<span class="linenr">142: </span>
<span class="linenr">143: </span># =========================
<span class="linenr">144: </span># 8) プロット（真値 vs 予測）
<span class="linenr">145: </span># =========================
<span class="linenr">146: </span>plt.figure(figsize=(12, 6))
<span class="linenr">147: </span>plt.plot(plot_index, true_inv, label="True")
<span class="linenr">148: </span>plt.plot(plot_index, pred_inv, label="Predicted")
<span class="linenr">149: </span>plt.title(f"Google Trends: {KEYWORD}  — LSTM Prediction vs True")
<span class="linenr">150: </span>plt.xlabel("Date")
<span class="linenr">151: </span>plt.ylabel("Trend index (0–100)")
<span class="linenr">152: </span>plt.legend()
<span class="linenr">153: </span>plt.tight_layout()
<span class="linenr">154: </span>plt.show()
<span class="linenr">155: </span>
<span class="linenr">156: </span># =========================
<span class="linenr">157: </span># 9)数ステップ先の再帰予測（テスト末尾から先へ）
<span class="linenr">158: </span># =========================
<span class="linenr">159: </span># 直近の実データ（学習+テストの最後のSEQ_LEN点）を使って、kステップ先まで再帰的に予測
<span class="linenr">160: </span>K_STEPS = 12
<span class="linenr">161: </span>hist_full = scaler.transform(series.values.reshape(-1,1)).flatten()
<span class="linenr">162: </span>window = hist_full[-SEQ_LEN:].copy()
<span class="linenr">163: </span>
<span class="linenr">164: </span>future_scaled = []
<span class="linenr">165: </span>model.eval()
<span class="linenr">166: </span>with torch.no_grad():
<span class="linenr">167: </span>    for _ in range(K_STEPS):
<span class="linenr">168: </span>        xin = torch.tensor(window, dtype=torch.float32).view(1, SEQ_LEN, 1).to(device)
<span class="linenr">169: </span>        yhat = model(xin).cpu().item()
<span class="linenr">170: </span>        future_scaled.append(yhat)
<span class="linenr">171: </span>        # 窓を1つ進める
<span class="linenr">172: </span>        window = np.concatenate([window[1:], [yhat]])
<span class="linenr">173: </span>
<span class="linenr">174: </span>future = scaler.inverse_transform(np.array(future_scaled).reshape(-1,1)).flatten()
<span class="linenr">175: </span>future_index = pd.date_range(series.index[-1], periods=K_STEPS+1, freq=series.index.inferred_freq)[1:]
<span class="linenr">176: </span>
<span class="linenr">177: </span>plt.figure(figsize=(12, 4))
<span class="linenr">178: </span>plt.plot(series.index[-100:], series.values[-100:], label="History (last 100)")
<span class="linenr">179: </span>plt.plot(future_index, future, label=f"Recursive forecast (+{K_STEPS})")
<span class="linenr">180: </span>plt.title(f"Google Trends: {KEYWORD} — Recursive Forecast")
<span class="linenr">181: </span>plt.xlabel("Date")
<span class="linenr">182: </span>plt.ylabel("Trend index (0–100)")
<span class="linenr">183: </span>plt.legend()
<span class="linenr">184: </span>plt.tight_layout()
<span class="linenr">185: </span>plt.show()
</pre>
</div>
</div>
</div>



<div id="outline-container-orgd86ffde" class="outline-2">
<h2 id="orgd86ffde"><span class="section-number-2">4.</span> 演習</h2>
<div class="outline-text-2" id="text-4">
<ul class="org-ul">
<li>自分が興味ある単語のgoogleトレンドを学習させてみよう</li>
<li>「kステップ先まで再帰的に予測」の部分で再帰的な計算がなぜ必要なのか考察せよ</li>
</ul>
</div>
</div>


<div id="outline-container-org81947fe" class="outline-2">
<h2 id="org81947fe"><span class="section-number-2">5.</span> 課題</h2>
<div class="outline-text-2" id="text-5">
<ul class="org-ul">
<li>複数の単語のgoogleトレンドを学習させてみよう。例えば「高専」「大学」の２つのトレンドから「高専」のトレンドを予測させる。</li>
<li>複数の入力があるLSTMが、どれをを重視しているのか調べてみよう。例えば「高専」「大学」の２つのトレンドから「高専」のトレンドを予測させる場合に、どちらからの入力が重要とみなされているか？学習したニューラルネットの重みを見ればわかるはずだが、この重みを取り出すプログラムはどう作る？</li>
</ul>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">著者: Hirotaka Niitsuma</p>
<p class="email">Email: <a href="mailto:hirotakaniitsuma@omu.ac.jp">hirotakaniitsuma@omu.ac.jp</a></p>
<p class="creator"><a href="https://www.gnu.org/software/emacs/">Emacs</a> 29.1 (<a href="https://orgmode.org/">Org</a> mode 9.6.6)</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>

</body></html>